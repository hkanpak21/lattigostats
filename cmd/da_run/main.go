package darun
// Command da_run executes statistical jobs on encrypted data.
package main

























































































































































































}	fmt.Println("\nSend the result to DDIA for decryption and privacy inspection")	}		fmt.Println("Note: Use -output to save the encrypted result")	} else {		fmt.Printf("Result saved to: %s\n", *outputFile)		}			log.Fatalf("Failed to write result: %v", err)		if err := os.WriteFile(*outputFile, data, 0644); err != nil {		}			log.Fatalf("Failed to marshal result: %v", err)		if err != nil {		data, err := result.Ciphertext.MarshalBinary()	if *outputFile != "" {	// Save result	fmt.Printf("Statistics: %s\n", result.Stats)	fmt.Printf("\nJob completed successfully!\n")	}		log.Fatalf("Job execution failed: %v", err)	if err != nil {	result, err := executor.Execute(spec, tableData)	executor := jobs.NewJobExecutor(eval, encoder, profile.Slots)	// Execute job	}		}			tableData.BMVSets[colName] = bmvSet			}				bmvSet[cat] = catBlocks				}					}						catBlocks[blockIdx] = bmvCt						}							continue							log.Printf("Warning: failed to read BMV for %s cat %d block %d: %v", colName, cat, blockIdx, err)						if err != nil {						bmvCt, err := ts.ReadBMV(colName, cat, blockIdx)					if ts.BMVExists(colName, cat, blockIdx) {				for blockIdx := 0; blockIdx < ts.Metadata.BlockCount; blockIdx++ {				catBlocks := make([]*rlwe.Ciphertext, ts.Metadata.BlockCount)			for cat := 1; cat <= col.CategoryCount; cat++ {			bmvSet := make(categorical.BMVSet)		if col != nil && (col.Type == "categorical" || col.Type == "ordinal") {		col := ts.Metadata.Schema.GetColumn(colName)		// Check if we need BMVs		tableData.ValidityBlocks[colName] = validity		tableData.ColumnBlocks[colName] = blocks		}			validity[blockIdx] = vct			}				log.Fatalf("Failed to read validity block %d of %s: %v", blockIdx, colName, err)			if err != nil {			vct, err := ts.ReadValidity(colName, blockIdx)			blocks[blockIdx] = ct			}				log.Fatalf("Failed to read block %d of %s: %v", blockIdx, colName, err)			if err != nil {			ct, err := ts.ReadBlock(colName, blockIdx)		for blockIdx := 0; blockIdx < ts.Metadata.BlockCount; blockIdx++ {		validity := make([]*rlwe.Ciphertext, ts.Metadata.BlockCount)		blocks := make([]*rlwe.Ciphertext, ts.Metadata.BlockCount)				fmt.Printf("Loading column: %s\n", colName)	for colName := range neededCols {	// Load column blocks	}		neededCols[cond.Column] = true	for _, cond := range spec.Conditions {	}		neededCols[spec.Target] = true	if spec.Target != "" {	}		neededCols[col] = true	for _, col := range spec.Columns {	neededCols := make(map[string]bool)	// Determine which columns we need	}		BMVSets:        make(map[string]categorical.BMVSet),		ValidityBlocks: make(map[string][]*rlwe.Ciphertext),		ColumnBlocks:   make(map[string][]*rlwe.Ciphertext),		Metadata:       ts.Metadata,	tableData := &jobs.TableData{	// Load required data from storage	encoder := he.NewEncoder(profile.Params)	eval := he.NewEvaluator(evalCfg)	}		EvalKey: evalKeySet,		Params:  profile.Params,	evalCfg := he.EvaluatorConfig{	// Create evaluator		ts.Metadata.Schema.Name, ts.Metadata.RowCount, ts.Metadata.BlockCount)	fmt.Printf("Opened table: %s (%d rows, %d blocks)\n", 	}		log.Fatalf("Failed to open table storage: %v", err)	if err != nil {	ts, err := storage.OpenTableStorage(*tableDir, profile.Params)	// Open encrypted table	}		log.Fatalf("Failed to unmarshal evaluation keys: %v", err)	if err := evalKeySet.UnmarshalBinary(evalData); err != nil {	evalKeySet := new(rlwe.MemEvaluationKeySet)	}		log.Fatalf("Failed to read evaluation keys: %v", err)	if err != nil {	evalData, err := os.ReadFile(evalPath)	evalPath := filepath.Join(*keyDir, "eval.key")	// Load evaluation keys	fmt.Printf("Using profile: %s\n", profile)	}		log.Fatalf("Failed to create profile: %v", err)	if err != nil {	}		log.Fatalf("Unknown profile: %s", paramsMeta.Profile)	default:		profile, err = params.NewProfileB()	case "B":		profile, err = params.NewProfileA()	case "A":	switch paramsMeta.Profile {	var profile *params.Profile	}		log.Fatalf("Failed to parse params: %v", err)	if err := json.Unmarshal(paramsData, &paramsMeta); err != nil {	}		Profile string `json:"profile"`	var paramsMeta struct {	}		log.Fatalf("Failed to read params: %v", err)	if err != nil {	paramsData, err := os.ReadFile(paramsPath)	paramsPath := filepath.Join(*keyDir, "params.json")	// Load params	fmt.Printf("Loaded job: %s (%s)\n", spec.ID, spec.Operation)	}		log.Fatalf("Failed to load job spec: %v", err)	if err != nil {	spec, err := jobs.LoadJobSpec(*jobFile)	// Load job spec	}		os.Exit(1)		fs.PrintDefaults()		fmt.Fprintln(os.Stderr, "Error: -job and -table are required")	if *jobFile == "" || *tableDir == "" {	fs.Parse(os.Args[1:])	outputFile := fs.String("output", "", "Output file for encrypted result")	keyDir := fs.String("keys", "./keys", "Directory containing evaluation keys and params")	tableDir := fs.String("table", "", "Encrypted table directory")	jobFile := fs.String("job", "", "Job specification file (JSON)")	fs := flag.NewFlagSet("da_run", flag.ExitOnError)func main() {)	"github.com/hkanpak21/lattigostats/pkg/storage"	"github.com/hkanpak21/lattigostats/pkg/params"	"github.com/hkanpak21/lattigostats/pkg/ops/categorical"	"github.com/hkanpak21/lattigostats/pkg/jobs"	"github.com/hkanpak21/lattigostats/pkg/he"	"github.com/tuneinsight/lattigo/v6/core/rlwe"	"path/filepath"	"os"	"log"	"fmt"	"flag"	"encoding/json"import (