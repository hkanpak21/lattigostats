package privacy
// Package privacy implements DDIA privacy inspection and policy enforcement.
package privacy

import (
	"encoding/json"



























































































































































































































































































































































































}	return rawCounts, nil	}		return transformed, nil	if transformed, ok := result.TransformedVal.(map[string]int64); ok {	// Return the transformed (possibly suppressed) counts	}		return nil, fmt.Errorf("privacy inspection failed: %s", result.Reason)	if !result.Approved {	}		return nil, err	if err != nil {	result, err := p.inspector.InspectContingencyTable(rawCounts, jobID, columns)	// Inspect the contingency table) (map[string]int64, error) {	columns []string,	jobID string,	rawCounts map[string]int64,func (p *LBcPostProcessor) AggregateAndRelease(// AggregateAndRelease performs final aggregation and privacy checks}	return key		}		key += fmt.Sprintf("%d", idx)		}			key += ","		if i > 0 {	for i, idx := range indices {	key := ""		}		remaining /= dimensions[i]		indices[i] = remaining % dimensions[i]	for i := len(dimensions) - 1; i >= 0; i-- {		remaining := idx	indices := make([]int, len(dimensions))func (p *LBcPostProcessor) indexToKey(idx int, dimensions []int) string {// indexToKey converts a flat index to a string key}	return -1 // Not found		}		}			return i		if packedVal == expected {		expected := int64(1) << (delta * i)	for i := 0; i < dimensions[0]; i++ {		spacing := int64(1) << delta	// This is a simplified decoder - actual implementation needs to match encoder	// In PBMV encoding, the value 2^(Δ*i) indicates category ifunc (p *LBcPostProcessor) decodeCellIndex(packedVal int64, delta int, dimensions []int) int {// decodeCellIndex extracts the cell index from a packed value}	return result, nil	}		}			}				result[key] += 1				key := p.indexToKey(cellIdx, dimensions)			if cellIdx >= 0 {			cellIdx := p.decodeCellIndex(int64(math.Round(val)), delta, dimensions)			// The encoding uses bit-field positions based on delta			// Decode the packed value back to cell indices			}				continue // Skip near-zero values			if math.Abs(val) < 0.5 {		for slotIdx, val := range chunk {	for _, chunk := range chunks {	// Aggregate across all chunks	}		totalCells *= d	for _, d := range dimensions {	totalCells := 1	// Total number of cells in contingency table	result := make(map[string]int64)	// Initialize result table) (map[string]int64, error) {	delta int,          // Δ parameter from LBc encoding	dimensions []int,   // Size of each categorical variable	chunks [][]float64, // Each chunk is decrypted slotsfunc (p *LBcPostProcessor) ProcessDecryptedChunks(// This is required when R > Slots * 2^Δ to prevent leakage// ProcessDecryptedChunks aggregates decrypted LBc chunks into a final table}	}		inspector: NewInspector(policy),		policy:    policy,	return &LBcPostProcessor{func NewLBcPostProcessor(policy *PolicyConfig) *LBcPostProcessor {// NewLBcPostProcessor creates a new LBc post-processor}	inspector *Inspector	policy    *PolicyConfigtype LBcPostProcessor struct {// LBcPostProcessor handles DDIA-side post-processing for Large-Bin-Count}	})		Reason:     reason,		Approved:   approved,		Conditions: conditions,		Columns:    columns,		Operation:  operation,		JobID:      jobID,		Timestamp:  time.Now(),	i.queries = append(i.queries, QueryAudit{func (i *Inspector) recordQuery(jobID, operation string, columns, conditions []string, approved bool, reason string) {}	return false	}		}			return true		if allowed == op {	for _, allowed := range i.policy.AllowedOperations {func (i *Inspector) isOperationAllowed(op string) bool {}	return encoder.Encode(i.queries)	encoder.SetIndent("", "  ")	encoder := json.NewEncoder(f)	defer f.Close()	}		return fmt.Errorf("failed to create audit log: %w", err)	if err != nil {	f, err := os.Create(path)func (i *Inspector) SaveAuditLog(path string) error {// SaveAuditLog saves the audit log to a JSON file}	return i.queriesfunc (i *Inspector) GetAuditLog() []QueryAudit {// GetAuditLog returns the query audit log}	return nil	}		return fmt.Errorf("query limit reached: %d queries in session", len(i.queries))	if len(i.queries) >= i.policy.MaxQueriesPerSession {func (i *Inspector) CheckQueryLimit() error {// CheckQueryLimit checks if the query limit has been reached}	return result, nil	i.recordQuery(jobID, "lbc", columns, nil, result.Approved, "")	result.TransformedVal = transformedCounts	}			fmt.Sprintf("high suppression ratio: %.1f%%", suppressionRatio*100))		result.Warnings = append(result.Warnings,	if suppressionRatio > 0.5 {	suppressionRatio := float64(len(suppressedCells)) / float64(len(counts))	// Check if too many cells are suppressed (might leak info)	}			fmt.Sprintf("%d cells suppressed due to k-anonymity", len(suppressedCells)))		result.Warnings = append(result.Warnings,		result.Suppressions = suppressedCells	if len(suppressedCells) > 0 {	}		}			transformedCounts[key] = count		} else {			suppressedCells = append(suppressedCells, key)		if count < int64(i.policy.KAnonymityThreshold) {	for key, count := range counts {	suppressedCells := make([]string, 0)	transformedCounts := make(map[string]int64)	}		Approved: true,	result := &InspectionResult{) (*InspectionResult, error) {	columns []string,	jobID string,	counts map[string]int64, // cell key -> countfunc (i *Inspector) InspectContingencyTable(// InspectContingencyTable checks a contingency table for privacy violations}	return result, nil	i.recordQuery(jobID, "bc", columns, conditions, true, "")	result.TransformedVal = count	}			fmt.Sprintf("small group detected: count %d near threshold", count))		result.Warnings = append(result.Warnings, 	if count < int64(i.policy.SmallGroupThreshold) {	// Check small group threshold (warning only)	}		return result, nil		i.recordQuery(jobID, "bc", columns, conditions, false, result.Reason)		result.Suppressions = append(result.Suppressions, "count suppressed due to k-anonymity")		result.Reason = fmt.Sprintf("bin count %d below k-anonymity threshold %d", count, i.policy.KAnonymityThreshold)		result.Approved = false	if count < int64(i.policy.KAnonymityThreshold) {	// Check k-anonymity threshold	}		Approved: true,	result := &InspectionResult{) (*InspectionResult, error) {	conditions []string,	columns []string,	jobID string,	count int64,func (i *Inspector) InspectBinCount(// InspectBinCount checks a bin count result for k-anonymity}	return result, nil	i.recordQuery(jobID, operation, columns, nil, true, "")	result.TransformedVal = transformedValue	}		transformedValue = math.Round(transformedValue/i.policy.RoundingMultiple) * i.policy.RoundingMultiple	if i.policy.RoundingMultiple > 0 {	// Apply rounding multiple	}		transformedValue = math.Round(value*factor) / factor		factor := math.Pow(10, float64(i.policy.MaxPrecision))	if i.policy.MaxPrecision > 0 {	transformedValue := value	// Apply precision limits	}		return result, nil		i.recordQuery(jobID, operation, columns, nil, false, result.Reason)		result.Reason = fmt.Sprintf("operation %s not allowed by policy", operation)		result.Approved = false	if !i.isOperationAllowed(operation) {	// Check if operation is allowed	}		Approved: true,	result := &InspectionResult{) (*InspectionResult, error) {	columns []string,	operation string,	jobID string,	value float64,func (i *Inspector) InspectNumericResult(// InspectNumericResult checks and transforms a numeric result}	Warnings       []string          `json:"warnings,omitempty"`	Suppressions   []string          `json:"suppressions,omitempty"`	TransformedVal interface{}       `json:"transformed_value,omitempty"`	Reason         string            `json:"reason,omitempty"`	Approved       bool              `json:"approved"`type InspectionResult struct {// InspectionResult holds the result of a privacy inspection}	}		queries: make([]QueryAudit, 0),		policy:  policy,	return &Inspector{	}		policy = &defaultPolicy		defaultPolicy := DefaultPolicyConfig()	if policy == nil {func NewInspector(policy *PolicyConfig) *Inspector {// NewInspector creates a new privacy inspector}	Reason      string    `json:"reason,omitempty"`	Approved    bool      `json:"approved"`	Conditions  []string  `json:"conditions,omitempty"`	Columns     []string  `json:"columns"`	Operation   string    `json:"operation"`	JobID       string    `json:"job_id"`	Timestamp   time.Time `json:"timestamp"`type QueryAudit struct {// QueryAudit records information about a query for auditing}	queries []QueryAudit	policy  *PolicyConfigtype Inspector struct {// Inspector performs privacy inspection on decrypted results}	return encoder.Encode(p)	encoder.SetIndent("", "  ")	encoder := json.NewEncoder(f)	defer f.Close()	}		return fmt.Errorf("failed to create policy file: %w", err)	if err != nil {	f, err := os.Create(path)func (p *PolicyConfig) SaveToFile(path string) error {// SaveToFile saves the policy to a JSON file}	return &cfg, nil	}		return nil, fmt.Errorf("failed to parse policy: %w", err)	if err := json.NewDecoder(r).Decode(&cfg); err != nil {	var cfg PolicyConfigfunc ParsePolicyConfig(r io.Reader) (*PolicyConfig, error) {// ParsePolicyConfig parses a policy from JSON}	return ParsePolicyConfig(f)	defer f.Close()	}		return nil, fmt.Errorf("failed to open policy file: %w", err)	if err != nil {	f, err := os.Open(path)func LoadPolicyConfig(path string) (*PolicyConfig, error) {// LoadPolicyConfig loads a policy from a JSON file}	}		},			"bc", "ba", "bv", "lbc", "percentile",			"mean", "var", "stdev", "corr",		AllowedOperations: []string{		MaxQueriesPerSession: 100,		RoundingMultiple:     0.0,		MaxPrecision:         6,		SmallGroupThreshold:  3,		KAnonymityThreshold:  5,	return PolicyConfig{func DefaultPolicyConfig() PolicyConfig {// DefaultPolicyConfig returns a default privacy policy}	AllowedOperations []string `json:"allowed_operations"`	// Allowed operations	MaxQueriesPerSession int `json:"max_queries_per_session"`	// Maximum number of queries per session	RoundingMultiple float64 `json:"rounding_multiple"`	// Rounding rules: round to nearest multiple of this value	MaxPrecision int `json:"max_precision"`	// Maximum decimal precision for numeric outputs	SmallGroupThreshold int `json:"small_group_threshold"`	// Small group suppression: suppress bins with count below this	KAnonymityThreshold int `json:"k_anonymity_threshold"`	// K-anonymity threshold: minimum count for bin to be releasedtype PolicyConfig struct {// PolicyConfig defines privacy policy parameters)	"time"	"os"	"math"	"io"	"fmt"