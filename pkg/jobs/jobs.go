package jobs
// Package jobs provides JobSpec parsing, planning, and execution for statistical queries.
package jobs

import (
	"encoding/json"
	"fmt"
































































































































































































































































































































































































































}	return total, nil	}		}			}				return nil, fmt.Errorf("failed to add block %d: %w", i, err)			if err := e.eval.AddInPlace(total, blockSum); err != nil {		} else {			total = blockSum		if total == nil {		}			return nil, fmt.Errorf("failed to sum block %d: %w", i, err)		if err != nil {		blockSum, err := e.eval.SumSlots(r, e.slots)	for i, r := range results {	var total *rlwe.Ciphertext	// Sum all results	}		return nil, err	if err != nil {	results, err := e.approxOps.TableLookup(catBlocks, numBlocks, targetCat, &cfg)	cfg := approx.DefaultDiscreteEqualZeroConfig(col.CategoryCount)	}		return nil, fmt.Errorf("column %s not found in schema", catCol)	if col == nil {	col := data.Metadata.Schema.GetColumn(catCol)	targetCat := spec.Conditions[0].Value	}		return nil, fmt.Errorf("numeric column %s not found", numCol)	if !ok {	numBlocks, ok := data.ColumnBlocks[numCol]	}		return nil, fmt.Errorf("categorical column %s not found", catCol)	if !ok {	catBlocks, ok := data.ColumnBlocks[catCol]	numCol := spec.Columns[1]	catCol := spec.Columns[0]func (e *JobExecutor) executeLookup(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.ordinalOps.Percentile(bmvBlocks, col.CategoryCount, &cfg)	cfg := ordinal.DefaultPercentileConfig(spec.K)	}		bmvBlocks[cat] = blocks	for cat, blocks := range bmvSet {	bmvBlocks := make(map[int][]*rlwe.Ciphertext)	// Convert BMVSet to the format expected by ordinal ops	}		return nil, fmt.Errorf("BMV set for column %s not found", colName)	if !ok {	bmvSet, ok := data.BMVSets[colName]	}		return nil, fmt.Errorf("percentile requires ordinal column, got %s", col.Type)	if col.Type != schema.Ordinal {	}		return nil, fmt.Errorf("column %s not found in schema", colName)	if col == nil {	col := data.Metadata.Schema.GetColumn(colName)	// Get the column's schema to find category count	colName := spec.Columns[0]func (e *JobExecutor) executePercentile(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.categoricalOps.BinVariance(targetBlocks, validity, data.BMVSets, conditions)	}		}			Value:      c.Value,			ColumnName: c.Column,		conditions[i] = categorical.Condition{	for i, c := range spec.Conditions {	conditions := make([]categorical.Condition, len(spec.Conditions))	}		return nil, fmt.Errorf("validity for target column %s not found", spec.Target)	if !ok {	validity, ok := data.ValidityBlocks[spec.Target]	}		return nil, fmt.Errorf("target column %s not found", spec.Target)	if !ok {	targetBlocks, ok := data.ColumnBlocks[spec.Target]func (e *JobExecutor) executeBinVar(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.categoricalOps.BinAverage(targetBlocks, validity, data.BMVSets, conditions)	}		}			Value:      c.Value,			ColumnName: c.Column,		conditions[i] = categorical.Condition{	for i, c := range spec.Conditions {	conditions := make([]categorical.Condition, len(spec.Conditions))	}		return nil, fmt.Errorf("validity for target column %s not found", spec.Target)	if !ok {	validity, ok := data.ValidityBlocks[spec.Target]	}		return nil, fmt.Errorf("target column %s not found", spec.Target)	if !ok {	targetBlocks, ok := data.ColumnBlocks[spec.Target]func (e *JobExecutor) executeBinAvg(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.categoricalOps.BinCount(validity, data.BMVSets, conditions)	}		}			Value:      c.Value,			ColumnName: c.Column,		conditions[i] = categorical.Condition{	for i, c := range spec.Conditions {	conditions := make([]categorical.Condition, len(spec.Conditions))	}		}			break			validity = v		for _, v := range data.ValidityBlocks {		// Try to get any validity block	if !ok {	validity, ok := data.ValidityBlocks[spec.Conditions[0].Column]	// Get validity blocks (use first condition's column)func (e *JobExecutor) executeBinCount(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.numericOps.Correlation(blocks1, blocks2, validity)	}		return nil, fmt.Errorf("validity for column %s not found", col1)	if !ok {	validity, ok := data.ValidityBlocks[col1]	// Use validity from first column (or could intersect)	}		return nil, fmt.Errorf("column %s not found", col2)	if !ok {	blocks2, ok := data.ColumnBlocks[col2]	}		return nil, fmt.Errorf("column %s not found", col1)	if !ok {	blocks1, ok := data.ColumnBlocks[col1]	col1, col2 := spec.Columns[0], spec.Columns[1]func (e *JobExecutor) executeCorr(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.numericOps.StdDev(blocks, validity)	}		return nil, fmt.Errorf("validity for column %s not found", colName)	if !ok {	validity, ok := data.ValidityBlocks[colName]	}		return nil, fmt.Errorf("column %s not found", colName)	if !ok {	blocks, ok := data.ColumnBlocks[colName]	colName := spec.Columns[0]func (e *JobExecutor) executeStdDev(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.numericOps.Variance(blocks, validity)	}		return nil, fmt.Errorf("validity for column %s not found", colName)	if !ok {	validity, ok := data.ValidityBlocks[colName]	}		return nil, fmt.Errorf("column %s not found", colName)	if !ok {	blocks, ok := data.ColumnBlocks[colName]	colName := spec.Columns[0]func (e *JobExecutor) executeVariance(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return e.numericOps.Mean(blocks, validity)	}		return nil, fmt.Errorf("validity for column %s not found", colName)	if !ok {	validity, ok := data.ValidityBlocks[colName]	}		return nil, fmt.Errorf("column %s not found", colName)	if !ok {	blocks, ok := data.ColumnBlocks[colName]	colName := spec.Columns[0]func (e *JobExecutor) executeMean(spec *JobSpec, data *TableData) (*rlwe.Ciphertext, error) {}	return result, nil	result.Stats = e.eval.GetStats()	result.Ciphertext = ct	}		return result, err		result.Error = err.Error()	if err != nil {	}		err = fmt.Errorf("unsupported operation: %s", spec.Operation)	default:		ct, err = e.executeLookup(spec, data)	case OpLookup:		ct, err = e.executePercentile(spec, data)	case OpPercentile:		ct, err = e.executeBinVar(spec, data)	case OpBinVar:		ct, err = e.executeBinAvg(spec, data)	case OpBinAvg:		ct, err = e.executeBinCount(spec, data)	case OpBinCount:		ct, err = e.executeCorr(spec, data)	case OpCorr:		ct, err = e.executeStdDev(spec, data)	case OpStdDev:		ct, err = e.executeVariance(spec, data)	case OpVariance:		ct, err = e.executeMean(spec, data)	case OpMean:	switch spec.Operation {	var err error	var ct *rlwe.Ciphertext	}		Operation: spec.Operation,		JobID:     spec.ID,	result := &JobResult{	}		return &JobResult{JobID: spec.ID, Error: err.Error()}, err	if err := spec.Validate(); err != nil {func (e *JobExecutor) Execute(spec *JobSpec, data *TableData) (*JobResult, error) {// Execute runs a job spec on the provided table data}	BMVSets        map[string]categorical.BMVSet         // columnName -> BMV set	ValidityBlocks map[string][]*rlwe.Ciphertext         // columnName -> validity blocks	ColumnBlocks   map[string][]*rlwe.Ciphertext         // columnName -> blocks	Metadata       *schema.TableMetadatatype TableData struct {// TableData holds encrypted table data for job execution}	}		slots:          slots,		ordinalOps:     ordinal.NewOrdinalOps(eval, encoder, slots),		approxOps:      approx.NewApproxOps(eval, encoder, slots),		categoricalOps: categorical.NewCategoricalOps(eval, encoder, slots),		numericOps:     numeric.NewNumericOps(eval, encoder, slots),		encoder:        encoder,		eval:           eval,	return &JobExecutor{func NewJobExecutor(eval *he.Evaluator, encoder *he.Encoder, slots int) *JobExecutor {// NewJobExecutor creates a new job executor}	slots          int	ordinalOps     *ordinal.OrdinalOps	approxOps      *approx.ApproxOps	categoricalOps *categorical.CategoricalOps	numericOps     *numeric.NumericOps	encoder        *he.Encoder	eval           *he.Evaluatortype JobExecutor struct {// JobExecutor executes job specs on encrypted data}	Error      string             `json:"error,omitempty"`	Stats      *he.Stats          `json:"-"` // Execution statistics	Ciphertext *rlwe.Ciphertext   `json:"-"` // Encrypted result	Operation  OperationType      `json:"operation"`	JobID      string             `json:"job_id"`type JobResult struct {// JobResult holds the result of a job execution}	return encoder.Encode(j)	encoder.SetIndent("", "  ")	encoder := json.NewEncoder(f)	defer f.Close()	}		return fmt.Errorf("failed to create job spec file: %w", err)	if err != nil {	f, err := os.Create(path)func (j *JobSpec) SaveToFile(path string) error {// SaveJobSpec saves a job spec to a JSON file}	return &spec, nil	}		return nil, fmt.Errorf("invalid job spec: %w", err)	if err := spec.Validate(); err != nil {	}		return nil, fmt.Errorf("failed to parse job spec: %w", err)	if err := json.NewDecoder(r).Decode(&spec); err != nil {	var spec JobSpecfunc ParseJobSpec(r io.Reader) (*JobSpec, error) {// ParseJobSpec parses a job spec from JSON}	return ParseJobSpec(f)	defer f.Close()	}		return nil, fmt.Errorf("failed to open job spec: %w", err)	if err != nil {	f, err := os.Open(path)func LoadJobSpec(path string) (*JobSpec, error) {// LoadJobSpec loads a job spec from a JSON file}	return nil	}		return fmt.Errorf("unknown operation: %s", j.Operation)	default:		// LBc has its own validation	case OpLargeBc:		}			return fmt.Errorf("lookup requires exactly 1 condition")		if len(j.Conditions) != 1 {		}			return fmt.Errorf("lookup requires at least 2 columns (categorical, numeric)")		if len(j.Columns) < 2 {	case OpLookup:		}			return fmt.Errorf("percentile k must be between 0 and 100")		if j.K < 0 || j.K > 100 {		}			return fmt.Errorf("percentile requires exactly 1 column")		if len(j.Columns) != 1 {	case OpPercentile:		}			return fmt.Errorf("%s requires a target column", j.Operation)		if j.Target == "" {	case OpBinAvg, OpBinVar:		}			return fmt.Errorf("bc requires at least 1 condition")		if len(j.Conditions) == 0 {	case OpBinCount:		}			return fmt.Errorf("corr requires exactly 2 columns, got %d", len(j.Columns))		if len(j.Columns) != 2 {	case OpCorr:		}			return fmt.Errorf("%s requires exactly 1 column, got %d", j.Operation, len(j.Columns))		if len(j.Columns) != 1 {	case OpMean, OpVariance, OpStdDev:	switch j.Operation {	}		return fmt.Errorf("job ID is required")	if j.ID == "" {func (j *JobSpec) Validate() error {// Validate checks that the job spec is valid}	Description string                 `json:"description,omitempty"` // Human-readable description	PolicyTag   string                 `json:"policy_tag,omitempty"`  // Privacy policy identifier	K           float64                `json:"k,omitempty"`           // Percentile value (0-100)	Conditions  []CategoricalCondition `json:"conditions,omitempty"`  // Filter conditions	Target      string                 `json:"target,omitempty"`      // Target numeric column for Ba/Bv	Columns     []string               `json:"columns"`               // Input columns (1 for mean/var, 2 for corr)	Operation   OperationType          `json:"operation"`	ID          string                 `json:"id"`type JobSpec struct {// JobSpec defines a statistical query to execute}	Value  int    `json:"value"`	Column string `json:"column"`type CategoricalCondition struct {// CategoricalCondition represents a filter condition (column = value))	OpLookup     OperationType = "lookup"	OpPercentile OperationType = "percentile"	OpLargeBc    OperationType = "lbc"	OpBinVar     OperationType = "bv"	OpBinAvg     OperationType = "ba"	OpBinCount   OperationType = "bc"	OpCorr       OperationType = "corr"	OpStdDev     OperationType = "stdev"	OpVariance   OperationType = "var"	OpMean       OperationType = "mean"const (type OperationType string// OperationType identifies the statistical operation to perform)	"github.com/hkanpak21/lattigostats/pkg/schema"	"github.com/hkanpak21/lattigostats/pkg/ops/ordinal"	"github.com/hkanpak21/lattigostats/pkg/ops/numeric"	"github.com/hkanpak21/lattigostats/pkg/ops/categorical"	"github.com/hkanpak21/lattigostats/pkg/ops/approx"	"github.com/hkanpak21/lattigostats/pkg/he"	"github.com/tuneinsight/lattigo/v6/core/rlwe"	"os"	"io"